{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbjXcy+iujFMkx03m+le5k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcnature/PSY292_2024Fall/blob/main/HW_CH11_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing between two hypotheses\n",
        "## Estimating posterior distribution\n",
        "\n",
        "This homework problem is a prelude for next class.\n",
        "\n",
        "- Task 1: estimating posterior distribution for the coin flipping.\n",
        "\n",
        "If you scroll to the section **Estimating posterior distributions** of this [notebook](https://colab.research.google.com/github/lcnature/statsthinking21-python/blob/master/notebooks/10-BayesianStatistics.ipynb#scrollTo=tAV1tMur3VQu), you should find an example in which we estimated the posterior probability distribution of the probability that patients respond to a drug. Its logic is very similar to the example of flipping coins, in which we want to estimate the posterior probability distribution of the chance that a coin lands on head.\n",
        "\n",
        "Let's assume we flip a coin for 100 times, and 70 times it lands on head.\n",
        "Please adapt the code in the example of the notebook above to plot the posterior distribution of the coin's probability of landing on head, based on this observation.\n",
        "\n",
        "You might find the curve different from the one you saw in class. Think of why."
      ],
      "metadata": {
        "id": "xcsnhNRzIhrQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcVXqVKeIWNB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Task 2: Comparing the marginal likelihood of two hypotheses.\n",
        "\n",
        "We may have two hypotheses: (1) $H_1$: the coin is fair, which means its probability of landing on head is exactly 0.5, $p_{head}=0.5$. (2) $H_2$: the coin's probability of landing on head $p_{head}$ is not exactly 0.5, but can take any value between 0 and 1 (we do not have specific guess of the probability).\n",
        "\n",
        "To know which hypothesis supports the data better, we can compute the posterior probabilities of each hypothesis, given the data (note that in the class, we treat each of 100 bins in the range of [0,1] as one hypothesis for $p_{head}$; here we summarize the uninformative uniform prior of $p_{head}$ used in class as a hypothesis $H_2$ that says $p_{head}$ does not necessarily equal to 0.5 exactly. This is analogous to what we do in null hypothesis statistical testing, in which null hypothesis usually assumes a parameter is exactly equal to a number, while the alternative hypothesis says the parameter can be of any value in a wide range). If we do not favor either of the hypotheses, we can assume they have equal prior probabilities (0.5). Then, comparing posterior probabilities is equivalent to comparing the marginal likelihood of each hypothesis (recall in the equation of Bayes theorem, posterior is proportional to the product of likelihood and prior).\n",
        "\n",
        "In $H_2$, if we are agnostic of the head-landing probability, we can use a uniform prior (this is a prior over $p_{head}$, under the assumption of $H_2$, which is exactly what we did in Task 1). So the likelihood $p(Data|H_2)$ is essentially the marginal likelihood $p(Data)$ in Task 1.\n",
        "\n",
        "Now, you simply need to compute $p(Data|H_1)$.\n",
        "\n",
        "After calculating $p(Data|H_1)$ and $p(Data|H_2)$, which of the hypotheses is more favored?\n",
        "Calculate the ratio $\\frac{p(Data|H_2)}{p(Data|H_1)}$ to answer this question (if it is larger than 1, then hypothesis 2 is more supported by the data).\n"
      ],
      "metadata": {
        "id": "JLX-BUODK8PC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MCS3DnQULVzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Task 3: Repeat task 2, but this time let's assume we observed 52 heads in 100 flipping of the coin (note the marginal likelihoods for both hypotheses need to be re-calculated because data are different). Now, how does the ratio change?"
      ],
      "metadata": {
        "id": "Du3Xn2qYNzJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fgNWd_TwPwZ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}